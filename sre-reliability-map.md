# SRE / 信頼性エンジニアリングマップ — 「どうシステムの信頼性を担保するか」

> ソフトウェアエンジニアリングの手法で運用の問題を解決する。
> **「100%の信頼性は目指さない。適切な信頼性を、エンジニアリングで実現する」** という思想のもと、
> 必要な工程・タスク・リソース・成果物を網羅的に整理したもの

このドキュメントは、SRE（Site Reliability Engineering）実践の全体像をマップしたものです。信頼性を担保するためには、単なるツール導入ではなく、組織体制・測定指標・自動化・インシデント対応・継続的な改善が一体となって機能する必要があります。以下の8つの核となる工程と、それに関連する横断的な視点を通じて、「どのように実装するか」を具体的に示します。各セクションはステップバイステップで実行可能になっており、組織の成熟度に応じて段階的に導入することができます。

## サービスマネジメント（ITIL）との比較

SREとサービスマネジメント（ITIL）は、どちらもシステムの信頼性と品質を目指していますが、その手法や思想が異なります。以下の図表は、両者の根本的な違いを示しています。ITILはプロセスと人による手順書ベースの運用を重視するのに対し、SREはソフトウェアエンジニアリングと自動化を通じた運用を実現する点が特徴です。

```mermaid
graph TB
    subgraph ITIL["ITIL / サービスマネジメント"]
        direction TB
        I1["プロセス重視"] --> I2["手順書ベース"]
        I2 --> I3["人による運用"]
    end

    subgraph SRE["SRE / 信頼性エンジニアリング"]
        direction TB
        S1["エンジニアリング重視"] --> S2["コードベース"]
        S2 --> S3["自動化による運用"]
    end

    style I3 fill:#E67E22,color:#fff
    style S3 fill:#27AE60,color:#fff
```

| 観点             | ITIL / ITSM                        | SRE                                            |
| ---------------- | ---------------------------------- | ---------------------------------------------- |
| 哲学             | ベストプラクティスのフレームワーク | ソフトウェアで運用問題を解決                   |
| 信頼性目標       | SLA（契約）                        | SLO（内部目標、SLAより厳しい）                 |
| 変更への態度     | CABによる承認制御                  | エラーバジェットによる自律的判断               |
| 自動化           | 推奨                               | 必須（Toil排除）                               |
| インシデント対応 | プロセスベース                     | ポストモーテム文化・ブレームレス               |
| 中心人物         | サービスマネージャー               | SRE（ソフトウェアエンジニア + オペレーション） |

## SRE 全体像

SREの8つの核となる工程は、相互に連関しながら一つの循環を形成しています。以下の図は、これらの工程の実行順序と、学習・改善のフィードバックループを示しています。SLI/SLOの定義から始まり、インシデント対応とポストモーテムを通じた改善が、再びSLI/SLOの最適化へと繋がることで、継続的な信頼性向上を実現します。

```mermaid
flowchart TB
    A["1. SLI/SLO<br>定義"] --> B["2. エラー<br>バジェット管理"]
    B --> C["3. Toil排除<br>＆自動化"]
    C --> D["4. 可観測性<br>（Observability）"]
    D --> E["5. インシデント<br>レスポンス"]
    E --> F["6. ポスト<br>モーテム"]
    F --> G["7. キャパシティ<br>プランニング"]
    G --> H["8. リリース<br>エンジニアリング"]

    F -.->|"学習→改善"| A
    D -.->|"データ"| B
    H -.->|"デプロイ→観測"| D

    style A fill:#8E44AD,color:#fff
    style B fill:#C0392B,color:#fff
    style C fill:#E67E22,color:#fff
    style D fill:#2980B9,color:#fff
    style E fill:#C0392B,color:#fff
    style F fill:#16A085,color:#fff
    style G fill:#27AE60,color:#fff
    style H fill:#2C3E50,color:#fff
```

## SRE の原則

SREの実践を支える基本原則は、上述の8つの工程を貫く哲学的な指針です。これらの原則が一貫していることで、組織全体がブレることなく信頼性エンジニアリングに取り組むことができます。

```mermaid
graph TD
    subgraph Principles["SRE の基本原則"]
        P1["Embracing Risk<br>（リスクを受け入れる）"]
        P2["SLI / SLO / SLA<br>（信頼性の定量化）"]
        P3["Eliminating Toil<br>（手作業の排除）"]
        P4["Monitoring & Observability<br>（可観測性）"]
        P5["Release Engineering<br>（リリースの自動化）"]
        P6["Simplicity<br>（シンプルさ）"]
    end

    P1 --> P2
    P2 --> P3
    P3 --> P4
    P4 --> P5
    P5 --> P6

    style P1 fill:#E74C3C,color:#fff
    style P2 fill:#3498DB,color:#fff
    style P3 fill:#F39C12,color:#fff
    style P4 fill:#2ECC71,color:#fff
    style P5 fill:#9B59B6,color:#fff
    style P6 fill:#1ABC9C,color:#fff
```

## 1. SLI / SLO / SLA 定義

### 目的

サービスの信頼性を**定量的に測定可能な指標**として定義し、「どの程度の信頼性が必要か」をステークホルダーと合意する。このステップは、後続のすべての意思決定（エラーバジェット管理、リリース判断、キャパシティプランニング）の基礎となるため、SREの最初にして最も重要な工程です。曖昧な「信頼性が高い」という定義ではなく、測定可能で納得性のある指標を設定することで、異なる視点を持つチーム間の合意形成が円滑になります。

### SLI → SLO → SLA の階層

信頼性の定義は、３つの階層に分かれています。下の図は、具体的な指標（SLI）がどのように目標値（SLO）となり、さらに顧客向けの契約（SLA）へと翻訳されるかを示しています。各階層は異なる目的と対象を持っており、正しく使い分けることが重要です。

```mermaid
graph TD
    SLI["SLI（Service Level Indicator）<br>サービスレベル指標<br>例：成功リクエスト率, P99レイテンシ"]
    SLO["SLO（Service Level Objective）<br>内部目標<br>例：可用性 99.95%, P99 < 300ms"]
    SLA["SLA（Service Level Agreement）<br>顧客との契約<br>例：可用性 99.9%（SLOより緩い）"]

    SLI -->|"指標を<br>目標値で表現"| SLO
    SLO -->|"外部向けに<br>バッファを持たせる"| SLA

    style SLI fill:#3498DB,color:#fff
    style SLO fill:#E67E22,color:#fff
    style SLA fill:#C0392B,color:#fff
```

### タスク一覧

SLI/SLO定義では、ユーザーの実体験に基づいた指標設計が求められ、後続のすべての意思決定（エラーバジェット消費、リリース判断、キャパシティ計画）の精度を左右します。他フェーズより定性的な議論が多く、ビジネス理解度とエンジニアリング視点の融合が不可欠です。初期段階では測定基盤の実装スキルも重要になります。

| #   | タスク                             | 説明                                                                   |
| --- | ---------------------------------- | ---------------------------------------------------------------------- |
| 1   | クリティカルユーザージャーニー特定 | ユーザーにとって最も重要な操作フローを特定                             |
| 2   | SLI選定                            | 各ジャーニーに対する計測指標の選定（可用性・レイテンシ・正確性・鮮度） |
| 3   | SLI計測方法の実装                  | メトリクス収集パイプラインの構築                                       |
| 4   | SLO目標値の設定                    | 過去データとビジネス要件に基づく目標値の決定                           |
| 5   | SLOドキュメント作成                | SLO定義書の作成・関係者合意                                            |
| 6   | SLOダッシュボード構築              | リアルタイムSLO達成状況の可視化                                        |
| 7   | SLA策定（外部向け）                | SLOにバッファを持たせたSLAの設計・契約                                 |

### リソース

この段階ではビジネス側とエンジニアリング側の両視点が必要なため、SRE・PM・開発チームの協働が特徴です。後続フェーズではSREが主役となりますが、SLI/SLO定義では全員の理解が成功の鍵となります。メトリクス基盤への投資も初期段階で、多くの組織ではこの基盤整備に最初の工数が集中します。

| カテゴリ | リソース               | 備考                               |
| -------- | ---------------------- | ---------------------------------- |
| **人**   | SRE                    | SLI/SLO設計の主担当                |
| **人**   | プロダクトマネージャー | ビジネス目標との整合性確認         |
| **人**   | 開発チーム             | SLI計測の実装                      |
| **物**   | メトリクス基盤         | Prometheus, Datadog, CloudWatch 等 |
| **物**   | ダッシュボード         | Grafana, Datadog Dashboards 等     |
| **金**   | メトリクスストレージ費 | 時系列データの保存コスト           |

### 成果物

これらの成果物は、組織全体に信頼性目標の「唯一の情報源」として機能します。SLOダッシュボードはエラーバジェット管理フェーズで毎日参照され、SLOドキュメントはインシデント対応時の判断基準となり、SLI定義書は長期的な可観測性戦略の基礎設計に影響します。

| 成果物            | 形式           | 必須/任意                  |
| ----------------- | -------------- | -------------------------- |
| SLI定義書         | ドキュメント   | 必須                       |
| SLOドキュメント   | ドキュメント   | 必須                       |
| SLOダッシュボード | ダッシュボード | 必須                       |
| SLA契約書         | 契約書         | 必須（外部サービスの場合） |

## 2. エラーバジェット管理

### 目的

「どれだけの障害を許容できるか」を定量化し、**リリース速度と信頼性のバランス**を自律的に制御する。SLOで定義した目標を達成できない範囲（バジェット）を可視化することで、「これ以上リリースを続けるべきか、一度立ち止まって信頼性改善に注力すべきか」という判断を、エモーショナルではなくデータドリブンで行うことができます。

### エラーバジェットの概念

エラーバジェットは、「許容できる障害時間」を月間単位で数値化したものです。以下の図は、このバジェットがどのように消費され、それがリリース判断へどう影響するかを示しています。

```mermaid
graph LR
    subgraph Budget["エラーバジェット = 1 - SLO"]
        direction TB
        TOTAL["月間エラーバジェット<br>例：SLO 99.9% → 0.1% = 約43.8分/月"]
        CONSUMED["消費済み<br>（障害・エラーで消費）"]
        REMAINING["残バジェット<br>（リリース可能な余裕）"]
        TOTAL --> CONSUMED
        TOTAL --> REMAINING
    end

    REMAINING -->|"残あり"| FAST["リリース加速OK"]
    REMAINING -->|"残なし"| SLOW["リリース凍結<br>信頼性改善に注力"]

    style FAST fill:#27AE60,color:#fff
    style SLOW fill:#C0392B,color:#fff
```

### タスク一覧

エラーバジェット管理では、リアルタイム監視と迅速な判断を求められ、SLI/SLOフェーズとは異なり「データドリブンな意思決定」が全面的に前面に出ます。バジェット枯渇時のアクション判定（リリース一時凍結など）は組織全体への影響が大きく、ポリシーの透明性と実行の一貫性が信頼構築の鍵になります。

| #   | タスク                       | 説明                                               |
| --- | ---------------------------- | -------------------------------------------------- |
| 1   | エラーバジェット計算         | SLOに基づくバジェットの算出                        |
| 2   | バジェット消費の追跡         | 障害・エラーによるバジェット消費のリアルタイム監視 |
| 3   | エラーバジェットポリシー策定 | バジェット枯渇時のアクション定義（リリース凍結等） |
| 4   | バジェットレポーティング     | 週次/月次のバジェット消費レポート                  |
| 5   | リリース判断への活用         | バジェット残量に基づくリリース可否判断             |
| 6   | バジェット枯渇時の対応       | 信頼性改善へのリソースシフト                       |

### リソース

SLI/SLOフェーズとの大きな違いは、プロダクトチームが意思決定を担う点です。ダッシュボードの表示精度とアラート設定がSREの仕事を大きく左右し、うかつな設定はアラート疲れやバジェット逆張りリリースを招きます。前フェーズほどビジネス交渉は少なく、テクニカルな実装精度が重視されます。

| カテゴリ | リソース                       | 備考                           |
| -------- | ------------------------------ | ------------------------------ |
| **人**   | SRE                            | バジェット管理・ポリシー運用   |
| **人**   | プロダクトチーム               | バジェットに基づくリリース判断 |
| **物**   | エラーバジェットダッシュボード | Grafana等で構築                |
| **物**   | アラートシステム               | バジェット閾値でのアラート     |

### 成果物

ポリシードキュメントはプロダクト・SRE・経営層が参照する意思決定の羅針盤となり、ダッシュボードは毎週レビューされ、レポートはバジェット枯渇時の判断材料として直接リリース凍結につながります。これら成果物の信頼性がなければ、組織はバジェット管理を放棄することになります。

| 成果物                         | 形式           | 必須/任意 |
| ------------------------------ | -------------- | --------- |
| エラーバジェットポリシー       | ドキュメント   | 必須      |
| エラーバジェットダッシュボード | ダッシュボード | 必須      |
| バジェット消費レポート（月次） | レポート       | 必須      |

## 3. Toil排除＆自動化

### 目的

手作業的・反復的・自動化可能な運用作業（Toil）を特定し、エンジニアリングで排除する。**SREの時間の50%以上をエンジニアリング作業に充てる**。Toilは一見すると「今その場をしのぐ」ために必要に見えますが、サービス成長に伴って指数関数的に増加し、組織の足かせになります。Toilを排除することで、SRE自身が戦略的・建設的な改善に時間を割くことができるようになります。

### Toil の定義

Toilは「単なる面倒な作業」ではなく、複数の特性を合わせ持つ運用作業として定義されます。以下の図は、Toilを特性づける6つの要素を示しています。

```mermaid
graph LR
    TOIL["Toil とは"]
    C1["手動的<br>（Manual）"]
    C2["繰り返し的<br>（Repetitive）"]
    C3["自動化可能<br>（Automatable）"]
    C4["戦術的<br>（Tactical）"]
    C5["長期的価値なし<br>（No lasting value）"]
    C6["サービス成長に<br>比例して増加<br>（O(n) with service growth）"]

    TOIL --> C1
    TOIL --> C2
    TOIL --> C3
    TOIL --> C4
    TOIL --> C5
    TOIL --> C6

    style TOIL fill:#C0392B,color:#fff
```

### タスク一覧

Toilの排除は全社的な取り組みが必要で、特に「何がToilか」の定義が組織によって異なるため、定義段階での丁寧な議論が求められます。開発・インフラ・SREが協力し、短期的には投資（自動化開発）を厭わないマインドセットが重要です。SRE時間の50%以上をエンジニアリングに充てられるかどうかが、SRE成熟度を測る重要指標になります。

| #   | タスク                      | 説明                                                           |
| --- | --------------------------- | -------------------------------------------------------------- |
| 1   | Toil計測                    | 運用作業の棚卸し、Toil率（全作業時間に占めるToilの割合）の算出 |
| 2   | Toil分類・優先順位付け      | 自動化の効果・難易度によるROI分析                              |
| 3   | 自動化ツール/スクリプト開発 | Toilを排除するための自動化実装                                 |
| 4   | セルフサービス化            | 他チームが自律的にできるようにするUI/API/ツール提供            |
| 5   | 自動化テスト                | 自動化ツールの正常動作・フェイルセーフの検証                   |
| 6   | Toil率の継続的モニタリング  | 50%ルール（SRE時間の50%以上はエンジニアリング）の遵守確認      |

### リソース

Toil排除フェーズでは、単なるSREの自動化スキルだけでなく、プラットフォームエンジニアや開発チームとの連携が他フェーズより重要です。リソース配分としては投資期間が長く、短期的なコスト増加を覚悟する必要があります。しかし組織が成長するに従い、自動化への投資が確実なROIを生み出すため、経営層の理解と忍耐が不可欠です。

| カテゴリ | リソース                   | 備考                                 |
| -------- | -------------------------- | ------------------------------------ |
| **人**   | SRE                        | 自動化の設計・実装                   |
| **人**   | プラットフォームエンジニア | 共通基盤の自動化                     |
| **物**   | IaC ツール                 | Terraform, Pulumi, Ansible 等        |
| **物**   | ワークフロー自動化         | Argo Workflows, Temporal, Rundeck 等 |
| **物**   | スクリプト実行環境         | Python, Go, Bash 等                  |
| **金**   | 自動化開発工数             | 短期的には投資、長期でROI回収        |

### 成果物

Toil計測レポートは組織の信頼性投資判断の根拠となり、自動化ロードマップは経営層へのアカウンタビリティを示します。自動化ツール/スクリプトは後続フェーズ（可観測性、リリースエンジニアリング）で再利用され、Toil率ダッシュボードはSRE採用や予算配分の議論につながる重要な可視化手段です。

| 成果物                  | 形式             | 必須/任意 |
| ----------------------- | ---------------- | --------- |
| Toil計測レポート        | スプレッドシート | 必須      |
| 自動化ロードマップ      | ドキュメント     | 必須      |
| 自動化ツール/スクリプト | コード           | 必須      |
| Toil率ダッシュボード    | ダッシュボード   | 任意      |

## 4. 可観測性（Observability）

### 目的

システムの内部状態を外部出力から**理解できるようにする**。「何が起きているか」だけでなく「なぜ起きているか」を把握する。可観測性がなければ、インシデント発生時の対応は根拠のない推測に頼ることになります。同時に、可観測性があれば、本番環境でのデバッグやボトルネック特定が格段に容易になり、SREとしての問題解決能力が飛躍的に向上します。

### 可観測性の3本柱 + α

可観測性は、メトリクス・ログ・トレース・プロファイリングの4つの観点から構成されます。以下の図は、各観点がどのような情報を提供し、その先の意思決定にどう役立つかを示しています。

```mermaid
graph TD
    OBS["可観測性<br>（Observability）"]
    M["メトリクス<br>（Metrics）<br>数値の時系列データ"]
    L["ログ<br>（Logs）<br>イベントの記録"]
    T["トレース<br>（Traces）<br>リクエストの流れ"]
    P["プロファイリング<br>（Profiling）\<br>ソース消費の詳細"]

    OBS --> M
    OBS --> L
    OBS --> T
    OBS --> P

    M --> D["ダッシュボード<br>アラート"]
    L --> D2["ログ検索<br>異常検知"]
    T --> D3["分散トレーシング<br>ボトルネック特定"]
    P --> D4["CPU/メモリ<br>ホットスポット"]

    style OBS fill:#2C3E50,color:#fff
    style M fill:#3498DB,color:#fff
    style L fill:#27AE60,color:#fff
    style T fill:#E67E22,color:#fff
    style P fill:#9B59B6,color:#fff
```

### タスク一覧

可観測性構築は、RED/USEメソッド理解、OpenTelemetry運用、分散トレーシング設計など、深い技術知識と実装経験を求める高度なフェーズです。他フェーズより開発チームの計装実装協力が必須で、ツール間の統合設計能力も重要です。アラート設計では「何を監視するか」が次のインシデント対応の質を左右し、SRE視点での継続的チューニングが必要になります。

| #   | タスク                     | 説明                                                                             |
| --- | -------------------------- | -------------------------------------------------------------------------------- |
| 1   | メトリクス設計・収集       | RED（Rate/Error/Duration）、USE（Utilization/Saturation/Errors）メソッドに基づく |
| 2   | 構造化ログ設計             | JSON形式のログ、相関ID、ログレベル設計                                           |
| 3   | 分散トレーシング導入       | OpenTelemetry等によるリクエストトレーシング                                      |
| 4   | ダッシュボード構築         | SLI/SLOダッシュボード、サービスダッシュボード                                    |
| 5   | アラート設計               | SLO-based alerting、多段階アラート（Warning/Critical）                           |
| 6   | オンコールルーティング設定 | アラート→チーム→担当者のルーティング                                             |
| 7   | Runbook整備                | アラートごとの対応手順書                                                         |
| 8   | アラートチューニング       | ノイズ削減、アラート疲れの防止                                                   |

### リソース

前フェーズの自動化投資が活きる段階で、リソース配分も本格的になります。可観測性基盤費用は成長に伴い指数関数的に増加するため、データ保持戦略やサンプリング設計が重要です。Toil排除フェーズで構築した自動化基盤は、ここでのログ収集・メトリクス処理パイプラインに再利用され、シナジーが生まれます。オンコール体制の準備も本フェーズで始まります。

| カテゴリ | リソース         | 備考                                     |
| -------- | ---------------- | ---------------------------------------- |
| **人**   | SRE              | 可観測性戦略・アラート設計               |
| **人**   | 開発チーム       | 計装（Instrumentation）の実装            |
| **物**   | メトリクス基盤   | Prometheus + Grafana / Datadog           |
| **物**   | ログ基盤         | ELK Stack / Loki / Splunk / Datadog Logs |
| **物**   | トレーシング基盤 | Jaeger / Zipkin / Datadog APM / Tempo    |
| **物**   | OpenTelemetry    | 計装の統一規格                           |
| **物**   | オンコールツール | PagerDuty, OpsGenie                      |
| **金**   | 可観測性基盤費用 | データ量に比例（最大のコスト要因の一つ） |

### 成果物

これら成果物は次フェーズ（インシデント対応・ポストモーテム）の基盤となります。メトリクスカタログは組織の共有知識となり、Runbookは本番トラブルの「指南書」として直接的に価値を提供します。アラートポリシーとルーティングルールは、以降のインシデント対応効率を左右する最重要成果物です。

| 成果物                     | 形式                        | 必須/任意 |
| -------------------------- | --------------------------- | --------- |
| 可観測性戦略ドキュメント   | ドキュメント                | 必須      |
| メトリクスカタログ         | Wiki                        | 必須      |
| ダッシュボード一式         | ダッシュボード              | 必須      |
| アラートポリシー           | 設定ファイル / ドキュメント | 必須      |
| Runbook                    | Wiki / ドキュメント         | 必須      |
| アラートルーティングルール | 設定                        | 必須      |

## 5. インシデントレスポンス

### 目的

サービスの品質低下・障害を**迅速かつ体系的に対応**し、影響を最小化する。インシデント対応の質は、事前の準備（体制構築、ドキュメント整備、訓練）にかかっています。本番でパニックになっていては、冷静な判断も効果的なコミュニケーションも難しくなります。事前の仕込みを完璧にすることで、いざという時に組織が最高のパフォーマンスを発揮できるようにします。

### インシデントレスポンスのフロー

インシデント発生から復旧、クローズまでの流れを明確にすることで、対応時間を短縮し、判断ミスを減らします。以下の図は、Severityに応じた分岐を含む、実践的なレスポンスフローを示しています。

```mermaid
flowchart TD
    A["アラート発砲 or ユーザー報告"] --> B["オンコール担当が受電"]
    B --> C["影響評価<br>＆ Severity判定"]
    C --> D{"Severity"}
    D -->|"SEV1/SEV2"| E["インシデントコマンダー<br>（IC）任命"]
    D -->|"SEV3/SEV4"| F["通常対応フロー"]

    E --> G["War Room / 対応チャンネル開設"]
    G --> H["並行作業"]
    H --> H1["緩和策の実施<br>（Mitigate）"]
    H --> H2["ステークホルダー<br>コミュニケーション"]
    H --> H3["根本原因調査"]

    H1 --> I["復旧確認"]
    I --> J["インシデントクローズ"]
    J --> K["ポストモーテム実施"]

    style A fill:#C0392B,color:#fff
    style E fill:#E67E22,color:#fff
    style K fill:#27AE60,color:#fff
```

### タスク一覧

インシデント対応は他フェーズと異なり、本番での「実行速度」と「判断精度」が直接的にビジネス影響に転化します。チーム全体のストレス耐性、エスカレーション判断、ステークホルダー対応スキルなど、テクニカルだけでなくソフトスキルも求められる唯一のフェーズです。訓練（Game Day等）による体制検証が、他フェーズより重要です。

| #   | タスク                     | 説明                                         |
| --- | -------------------------- | -------------------------------------------- |
| 1   | オンコール体制構築         | ローテーション設計、エスカレーションパス定義 |
| 2   | Severity定義               | SEV1〜SEV4の基準と対応SLAの設定              |
| 3   | インシデントコマンダー制度 | IC/Communication Lead/Ops Leadの役割定義     |
| 4   | コミュニケーション計画     | ステータスページ更新、社内通知フロー         |
| 5   | インシデント対応訓練       | Wheel of Misfortune、Game Day等の実施        |
| 6   | 自動化された初動対応       | Auto-remediation、自動スケーリング等         |

### リソース

前フェーズとの大きな違いは、人的リソース配分が「チーム全体の24/7体制」へシフトすることです。可観測性基盤の充実度がオンコールの負担を大きく左右し、投資不足は即座に人的コストの増加につながります。重大インシデント時のコミュニケーション品質が企業イメージに直結するため、ツール以上に教育と訓練への投資が重要です。

| カテゴリ | リソース                 | 備考                                   |
| -------- | ------------------------ | -------------------------------------- |
| **人**   | インシデントコマンダー   | 重大インシデントの指揮                 |
| **人**   | オンコールエンジニア     | ローテーションで対応                   |
| **人**   | コミュニケーションリード | 外部・社内への状況報告                 |
| **物**   | オンコール管理           | PagerDuty, OpsGenie                    |
| **物**   | ステータスページ         | Statuspage.io, Cachet                  |
| **物**   | War Roomツール           | Slack / Teams のインシデントチャンネル |
| **金**   | オンコール手当           | 夜間・休日対応費用                     |

### 成果物

これら成果物は組織の信頼と透明性の象徴です。プレイブックはエンジニアの自信につながり、Severity定義書はステークホルダー間の期待値合意を生み出します。タイムラインと更新履歴はポストモーテム実施の基礎情報となり、次フェーズの学習駆動につながります。

| 成果物                       | 形式                    | 必須/任意         |
| ---------------------------- | ----------------------- | ----------------- |
| オンコールローテーション     | スケジュール            | 必須              |
| インシデント対応プレイブック | Wiki / ドキュメント     | 必須              |
| Severity定義書               | ドキュメント            | 必須              |
| インシデントタイムライン     | チケット / ドキュメント | 必須（SEV1/SEV2） |
| ステータスページ更新履歴     | ログ                    | 必須              |

## 6. ポストモーテム

### 目的

インシデントから**ブレームレス（責任追及なし）** で学び、再発防止策を実行して同じ失敗を繰り返さない。ポストモーテムは、SREの成熟度を最も象徴する活動です。組織が「誰が悪いか」という責任追及ではなく「何がシステムの脆弱性だったのか」という改善にフォーカスできるかどうかで、その後の信頼性向上のスピードが決まります。

### ポストモーテムのプロセス

ポストモーテムは、インシデント発生直後から始まるプロセスです。以下の図は、クローズから改善実行まで、どのような段階を経るかを示しています。

```mermaid
flowchart LR
    A["インシデント<br>クローズ"] --> B["タイムライン<br>作成"]
    B --> C["根本原因<br>分析"]
    C --> D["ポストモーテム<br>文書作成"]
    D --> E["レビュー<br>ミーティング"]
    E --> F["アクション<br>アイテム策定"]
    F --> G["アクション<br>実行・追跡"]

    style A fill:#C0392B,color:#fff
    style D fill:#2980B9,color:#fff
    style F fill:#27AE60,color:#fff
```

### ポストモーテムの原則

| 原則               | 説明                                                         |
| ------------------ | ------------------------------------------------------------ |
| **ブレームレス**   | 個人を責めない。システムやプロセスの問題にフォーカス         |
| **タイムリー**     | インシデントクローズ後48時間以内（記憶が新鮮なうちに）       |
| **アクション指向** | 「気をつける」ではなく、具体的・測定可能なアクションアイテム |
| **広く共有**       | 組織全体で学びを共有（ポストモーテム読書会等）               |
| **フォローアップ** | アクションアイテムの完了を追跡、放置しない                   |

### タスク一覧

ポストモーテムはSRE活動における「学習メカニズム」そのもので、ブレームレス文化の定着度、組織のシステム思考力、改善への実行力をすべて試される唯一のフェーズです。前フェーズのインシデント対応では「如何に早く復旧するか」に注力しますが、ここでは「なぜそれが起きたのか」への徹底的な掘り下げが求められ、根本原因分析スキルが最重要です。

| #   | タスク                 | 説明                                                |
| --- | ---------------------- | --------------------------------------------------- |
| 1   | タイムライン作成       | インシデントの時系列整理（検知→対応→復旧→クローズ） |
| 2   | 根本原因分析           | 5Whys、Fault Tree Analysis等                        |
| 3   | 影響分析               | ユーザー影響、ビジネス影響の定量化                  |
| 4   | ポストモーテム文書作成 | テンプレートに基づく文書化                          |
| 5   | レビューミーティング   | 関係者全員でのブレームレスレビュー                  |
| 6   | アクションアイテム策定 | 再発防止策の具体的タスク化                          |
| 7   | アクションアイテム追跡 | 完了までのフォローアップ                            |
| 8   | ポストモーテム共有     | 組織全体への学びの展開                              |

### 成果物

ポストモーテム文書は組織の信頼性改善の「羅針盤」であり、アクションアイテムの実行追跡により初めてインシデントが組織資産へと昇華されます。共有記録によって、将来の類似インシデント時には「過去の失敗から学ぶ」という好循環が生まれ、長期的な信頼性向上を加速させます。

| 成果物                   | 形式                         | 必須/任意 |
| ------------------------ | ---------------------------- | --------- |
| ポストモーテム文書       | ドキュメント（テンプレート） | 必須      |
| インシデントタイムライン | 図表 / ドキュメント          | 必須      |
| アクションアイテム一覧   | チケット                     | 必須      |
| ポストモーテム共有記録   | Wiki / メール                | 任意      |

## 7. キャパシティプランニング

### 目的

サービスの成長・需要変動に対して**十分なリソースを事前に確保**し、性能劣化やコスト超過を防ぐ。キャパシティプランニングが十分でないと、いくら他のSRE活動が優秀でも、ユーザーは遅いシステムを使わされることになります。逆に、過度にプロビジョニングすれば、組織は無駄なコストを背負うことになります。データドリブンな需要予測と段階的なスケーリングにより、信頼性とコスト効率の両立が実現します。

### タスク一覧

キャパシティプランニングでは、統計分析と負荷テストによるテクニカルなスキルに加え、ビジネス成長計画の理解、コスト最適化のポリティクス判断が求められます。ポストモーテムで得られた知見（頻出ボトルネック、障害パターン）を反映し、単なる容量計画を超えた「信頼性を支える基盤設計」が実現されます。

| #   | タスク               | 説明                                                         |
| --- | -------------------- | ------------------------------------------------------------ |
| 1   | 需要予測             | 過去トレンド・ビジネス計画に基づく将来需要の推定             |
| 2   | 負荷テスト           | 現在のキャパシティ上限の測定                                 |
| 3   | ボトルネック分析     | CPU/メモリ/ディスク/ネットワーク/DB等のボトルネック特定      |
| 4   | スケーリング戦略策定 | 水平/垂直スケーリング、オートスケーリングの設計              |
| 5   | コスト最適化         | リソースの適正化（Right-sizing）、リザーブドインスタンス活用 |
| 6   | N+1冗長性確保        | 障害時にも性能を維持できる冗長構成                           |

### リソース

ポストモーテムフェーズから引き継いだ「障害ボトルネックデータ」と、ここでの「負荷予測・スケーリング設計」が組み合わさることで、初めて信頼性と効率を両立したインフラが実現します。インフラ費用がSRE活動の成果の大きさを示す指標となり、経営層への説明責任が生じます。前フェーズのインシデント知見を直接的に活かすことが、他フェーズより強く求められます。

| カテゴリ | リソース           | 備考                                |
| -------- | ------------------ | ----------------------------------- |
| **人**   | SRE                | キャパシティ設計                    |
| **人**   | インフラエンジニア | リソース管理                        |
| **物**   | 負荷テストツール   | k6, Locust, JMeter, Gatling 等      |
| **物**   | クラウドコスト分析 | AWS Cost Explorer, GCP Billing 等   |
| **物**   | オートスケーラー   | Kubernetes HPA, AWS Auto Scaling 等 |
| **金**   | インフラ費用       | クラウドリソース / データセンター   |

### 成果物

キャパシティ計画書とスケーリングポリシーは経営層への信頼性・コスト説明の根拠となり、負荷テストレポートはリリースエンジニアリング段階での検証基準に活用されます。コスト最適化レポートは、信頼性投資の正当性をビジネス観点から証明する重要な成果物となります。

| 成果物               | 形式                | 必須/任意 |
| -------------------- | ------------------- | --------- |
| キャパシティ計画書   | ドキュメント        | 必須      |
| 負荷テストレポート   | レポート            | 必須      |
| コスト最適化レポート | スプレッドシート    | 必須      |
| スケーリングポリシー | 設定 / ドキュメント | 必須      |

## 8. リリースエンジニアリング

### 目的

ソフトウェアのビルド・テスト・デプロイを**安全・高速・再現可能**に行う仕組みを構築する。リリースエンジニアリングが十分でなければ、開発チームは本番デプロイに恐怖を感じ、必然的にリリース頻度が低下します。一方、完全に自動化され、信頼できるパイプラインがあれば、チームはオンデマンドで本番へコードをデプロイできるようになり、その結果、迅速な改善と信頼性向上が実現します。

### タスク一覧

リリースエンジニアリングは、前フェーズまでの可観測性・キャパシティ基盤を活かす「実行フェーズ」です。CI/CDパイプラインの品質が直接的にデプロイ頻度・変更失敗率といったDORAメトリクスに影響し、組織全体の開発速度を左右します。可観測性基盤の充実（自動検知・自動ロールバック）があってこそ、高い信頼度でのリリース加速が実現されます。

| #   | タスク                | 説明                                        |
| --- | --------------------- | ------------------------------------------- |
| 1   | CI/CDパイプライン構築 | ビルド→テスト→デプロイの自動化              |
| 2   | デプロイ戦略設計      | Blue-Green / Canary / Rolling Update の選定 |
| 3   | Feature Flags導入     | 機能のトグル制御によるリスク低減            |
| 4   | ロールバック自動化    | 異常検知時の自動ロールバック                |
| 5   | アーティファクト管理  | ビルド成果物のバージョニング・保管          |
| 6   | デプロイ頻度の向上    | リードタイムの短縮、バッチサイズの削減      |

### リソース

他フェーズと異なり、リソース配分の中心が「開発チーム全体」へシフトします。SREはパイプライン構築という初期投資を行いますが、その後は開発チームが日々利用する基盤となり、ROIが継続的に生じます。Toil排除フェーズで構築した自動化基盤の仕上げとして、ここでのパイプライン品質向上が全SRE活動の成果を左右する最終段階です。

| カテゴリ | リソース                 | 備考                                          |
| -------- | ------------------------ | --------------------------------------------- |
| **人**   | SRE / リリースエンジニア | パイプライン構築・運用                        |
| **人**   | 開発チーム               | パイプラインの利用                            |
| **物**   | CI/CD                    | GitHub Actions, GitLab CI, Jenkins, ArgoCD 等 |
| **物**   | コンテナレジストリ       | Docker Hub, ECR, GCR 等                       |
| **物**   | Feature Flagsツール      | LaunchDarkly, Unleash, Flagsmith 等           |
| **金**   | CI/CD実行費              | ビルドランナーのコスト                        |

### 成果物

CI/CDパイプラインは組織の開発生産性の「心臓」となり、その品質がDORAメトリクスを通じて可視化されます。これら成果物は開発チーム全体へ継続的に価値を提供し、本文書の冒頭で示した「SLI/SLOの定義→エラーバジェット管理→インシデント対応→改善」という循環を、実際のコード変更で実現するための最後の砦です。

| 成果物                        | 形式           | 必須/任意 |
| ----------------------------- | -------------- | --------- |
| CI/CDパイプライン             | コード（IaC）  | 必須      |
| デプロイ戦略ドキュメント      | ドキュメント   | 必須      |
| リリースプロセスガイド        | Wiki           | 必須      |
| DORA メトリクスダッシュボード | ダッシュボード | 任意      |

## 横断的な視点 — 他視点との関係

SRE活動は、組織内の他の機能（サービスマネジメント、プロダクト、セキュリティ、プラットフォームエンジニアリング）と密接に関連しています。以下の図は、SREがこれらの機能とどのように連携し、相互にどのような価値交換を行うかを示しています。組織全体で信頼性文化を醸成するには、これらの横断的な関係性が適切に機能していることが不可欠です。

```mermaid
graph TB
    SRE["SRE / 信頼性<br>エンジニアリング"]
    SM["サービス<br>マネジメント"]
    PD["プロダクト"]
    PJ["プロジェクト"]
    SEC["セキュリティ"]
    PE["プラットフォーム<br>エンジニアリング"]

    SRE -->|"SLI/SLO設計<br>自動化"| SM
    SM -->|"インシデントデータ<br>SLA要件"| SRE
    SRE -->|"信頼性データで<br>プロダクト改善"| PD
    PD -->|"品質要件<br>リリース要求"| SRE
    SRE -->|"セキュリティ<br>インシデント対応"| SEC
    PE -->|"プラットフォーム<br>自動化基盤"| SRE
    SRE -->|"要件フィード<br>バック"| PE

    style SRE fill:#E74C3C,color:#fff
```

### DORA メトリクスによるパフォーマンス計測

SREの活動成果は **DORA 4 Key Metrics** で測定します。このメトリクスは、組織のソフトウェア配信パフォーマンスの優劣を客観的に評価するための標準指標です。各メトリクスは、SLI/SLO定義から自動化、インシデント対応まで、SREの各工程の質が適切に反映されるため、組織全体の信頼性向上の進捗を追跡する上で欠かせません。以下の表は、Elite企業がどの程度のレベルを達成しているかを示しており、自組織の現状との比較を通じて、改善の優先順位が見えてきます。

| メトリクス       | 説明                 | Elite の基準              |
| ---------------- | -------------------- | ------------------------- |
| デプロイ頻度     | 本番デプロイの頻度   | オンデマンド（1日複数回） |
| リードタイム     | コミット→本番の時間  | 1時間未満                 |
| 変更失敗率       | デプロイ起因の障害率 | 0-15%                     |
| 復旧時間（MTTR） | 障害からの復旧時間   | 1時間未満                 |
